{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "### We chose to parse the dataset from Stanford as it has more information and characteristics than the one from Kaggle. The dataset from Kaggle is a subset of the one from Stanford, so we decided to use the original one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------+--------------------+---+---+-----------------+--------+--------+------+------------+-----------+---------------+---------+--------------------+---------------+--------------+--------+----------------+----------------+------------------+----------------+--------------+--------------+-------------+------------+-------------+------------+------------+---------------+------------------------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|raw_row_number|      date|    time|            location|lat|lng|      county_name|district|precinct|region|subject_race|subject_sex|officer_id_hash|     type|           violation|citation_issued|warning_issued| outcome|contraband_found|contraband_drugs|contraband_weapons|search_conducted|search_vehicle|  search_basis|vehicle_color|vehicle_make|vehicle_model|vehicle_type|vehicle_year|raw_HA_RACE_SEX|raw_HA_SEARCH_PC_boolean|raw_HA_SEARCH_CONCENT_boolean|raw_HA_INCIDTO_ARREST_boolean|raw_HA_VEHICLE_INVENT_boolean|\n",
      "+--------------+----------+--------+--------------------+---+---+-----------------+--------+--------+------+------------+-----------+---------------+---------+--------------------+---------------+--------------+--------+----------------+----------------+------------------+----------------+--------------+--------------+-------------+------------+-------------+------------+------------+---------------+------------------------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|             1|2006-01-01|00:00:00|route: 0030, mile...| NA| NA|    Walker County|       C|      NA|     2|       white|     female|     b754c6abf4|vehicular|Drive On Improved...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             WF|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|             2|2006-01-01|00:00:00|route: 0207, mile...| NA| NA|  Hansford County|       B|      11|     5|       white|       male|     7621d63a65|vehicular|Speeding-10% or M...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             WM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|             3|2006-01-01|00:00:00|route: 0105, mile...| NA| NA|Montgomery County|       C|      20|     2|    hispanic|       male|     2c0d24dbbd|vehicular|Open Container in...|           TRUE|         FALSE|citation|            TRUE|           FALSE|             FALSE|            TRUE|            NA|probable cause|           NA|          NA|           NA|          SV|          NA|             HM|                    TRUE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|             4|2006-01-01|00:00:00|route: 0010, mile...| NA| NA|  Chambers County|       B|      NA|     2|       white|       male|     1abde6b2cf|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          SV|          NA|             WM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|             5|2006-01-01|00:00:00|route: 1774, mile...| NA| NA|Montgomery County|       C|      50|     2|       white|       male|     3f1120d85a|vehicular|No/Improper Licen...|           TRUE|          TRUE|citation|            TRUE|           FALSE|             FALSE|            TRUE|            NA|probable cause|           NA|          NA|           NA|          PA|          NA|             WM|                    TRUE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|             8|2006-01-01|00:00:00|route: 0035, mile...| NA| NA|      Frio County|       B|      NA|     3|    hispanic|       male|     bb8d7daa5d|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             HM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|             9|2006-01-01|00:00:00|route: 0385, mile...| NA| NA|    Castro County|       B|      NA|     5|    hispanic|       male|     46512c3e98|vehicular|No/Improper Licen...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|             HM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            10|2006-01-01|00:00:00|route: 0511, mile...| NA| NA|   Cameron County|       A|      21|     8|    hispanic|       male|     d71bcea4a5|vehicular|Fail to Maintain ...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PV|          NA|             HM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            11|2006-01-01|00:00:00|route: 0020, mile...| NA| NA|  Eastland County|       B|      20|     4|    hispanic|       male|     bfaf4ea0b6|vehicular|Speeding-10% or M...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             HM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            12|2006-01-01|00:00:00|route: 0020, mile...| NA| NA| Van Zandt County|       B|      NA|     1|       white|       male|     9c1f3a985a|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             WM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            13|2006-01-01|00:00:00|route: 0287, mile...| NA| NA|  Anderson County|       C|      40|     6|       black|     female|     85d044df3d|vehicular|Fail To Display D...|           TRUE|          TRUE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             BF|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            14|2006-01-01|00:00:00|          route: 134| NA| NA|   Haskell County|       A|      10|     5|    hispanic|       male|     5d6ea74869|vehicular|Minor Consume Alc...|           TRUE|         FALSE|citation|            TRUE|           FALSE|             FALSE|            TRUE|            NA|probable cause|           NA|          NA|           NA|          PU|          NA|             HM|                    TRUE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            16|2006-01-01|00:00:00|          route: 134| NA| NA|   Haskell County|       A|      00|     5|       white|       male|     5d6ea74869|vehicular|Minor Consume Alc...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|             WM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            17|2006-01-01|00:01:00|route: 0059, mile...| NA| NA|   Wharton County|       C|      20|     2|       white|       male|     41cda6005f|vehicular|Speeding-10% or M...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             WM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            18|2006-01-01|00:01:00|route: 0021, mile...| NA| NA|   Bastrop County|       C|      NA|     6|       black|     female|     8b99d7010d|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             BF|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            19|2006-01-01|00:01:00|route: 0238, mile...| NA| NA|   Calhoun County|       A|      NA|     3|       black|       male|     92f60bd84f|vehicular|No/Improper Licen...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|             BM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            20|2006-01-01|00:01:00|route: 0281, mile...| NA| NA|   Hidalgo County|       A|      42|     8|       white|       male|     3d49aa825d|vehicular|Speeding-10% or M...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|             WM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            21|2006-01-01|00:01:00|route: 0256, mile...| NA| NA|  Anderson County|       C|      NA|     6|       white|     female|     85d044df3d|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             WF|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            22|2006-01-01|00:01:00|route: 0410, mile...| NA| NA|     Bexar County|       B|      20|     3|    hispanic|     female|     083d70bcc5|vehicular|Ride, Not Secured...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|             HF|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            23|2006-01-01|00:01:00|     route: FRONTAGE| NA| NA|   Cameron County|       A|      NA|     8|    hispanic|       male|     9d1b7b13f1|vehicular|No/Non-Compliant ...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             HM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "+--------------+----------+--------+--------------------+---+---+-----------------+--------+--------+------+------------+-----------+---------------+---------+--------------------+---------------+--------------+--------+----------------+----------------+------------------+----------------+--------------+--------------+-------------+------------+-------------+------------+------------+---------------+------------------------+-----------------------------+-----------------------------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('DataFrame Optimization') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the DataFrame\n",
    "df = spark.read.format('csv').option('header', 'true').load('../data/tx_statewide_2020_04_01.csv')\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19752786"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1426"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show number NaN values in violation column\n",
    "df.filter(df['violation'].isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove columns with name starting with \"raw_\" as they are not useful for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+---+---+-----------------+--------+--------+------+------------+-----------+---------------+---------+--------------------+---------------+--------------+--------+----------------+----------------+------------------+----------------+--------------+--------------+-------------+------------+-------------+------------+------------+\n",
      "|      date|    time|            location|lat|lng|      county_name|district|precinct|region|subject_race|subject_sex|officer_id_hash|     type|           violation|citation_issued|warning_issued| outcome|contraband_found|contraband_drugs|contraband_weapons|search_conducted|search_vehicle|  search_basis|vehicle_color|vehicle_make|vehicle_model|vehicle_type|vehicle_year|\n",
      "+----------+--------+--------------------+---+---+-----------------+--------+--------+------+------------+-----------+---------------+---------+--------------------+---------------+--------------+--------+----------------+----------------+------------------+----------------+--------------+--------------+-------------+------------+-------------+------------+------------+\n",
      "|2006-01-01|00:00:00|route: 0030, mile...| NA| NA|    Walker County|       C|      NA|     2|       white|     female|     b754c6abf4|vehicular|Drive On Improved...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|\n",
      "|2006-01-01|00:00:00|route: 0207, mile...| NA| NA|  Hansford County|       B|      11|     5|       white|       male|     7621d63a65|vehicular|Speeding-10% or M...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|\n",
      "|2006-01-01|00:00:00|route: 0105, mile...| NA| NA|Montgomery County|       C|      20|     2|    hispanic|       male|     2c0d24dbbd|vehicular|Open Container in...|           TRUE|         FALSE|citation|            TRUE|           FALSE|             FALSE|            TRUE|            NA|probable cause|           NA|          NA|           NA|          SV|          NA|\n",
      "|2006-01-01|00:00:00|route: 0010, mile...| NA| NA|  Chambers County|       B|      NA|     2|       white|       male|     1abde6b2cf|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          SV|          NA|\n",
      "|2006-01-01|00:00:00|route: 1774, mile...| NA| NA|Montgomery County|       C|      50|     2|       white|       male|     3f1120d85a|vehicular|No/Improper Licen...|           TRUE|          TRUE|citation|            TRUE|           FALSE|             FALSE|            TRUE|            NA|probable cause|           NA|          NA|           NA|          PA|          NA|\n",
      "|2006-01-01|00:00:00|route: 0035, mile...| NA| NA|      Frio County|       B|      NA|     3|    hispanic|       male|     bb8d7daa5d|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|\n",
      "|2006-01-01|00:00:00|route: 0385, mile...| NA| NA|    Castro County|       B|      NA|     5|    hispanic|       male|     46512c3e98|vehicular|No/Improper Licen...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|\n",
      "|2006-01-01|00:00:00|route: 0511, mile...| NA| NA|   Cameron County|       A|      21|     8|    hispanic|       male|     d71bcea4a5|vehicular|Fail to Maintain ...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PV|          NA|\n",
      "|2006-01-01|00:00:00|route: 0020, mile...| NA| NA|  Eastland County|       B|      20|     4|    hispanic|       male|     bfaf4ea0b6|vehicular|Speeding-10% or M...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|\n",
      "|2006-01-01|00:00:00|route: 0020, mile...| NA| NA| Van Zandt County|       B|      NA|     1|       white|       male|     9c1f3a985a|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|\n",
      "|2006-01-01|00:00:00|route: 0287, mile...| NA| NA|  Anderson County|       C|      40|     6|       black|     female|     85d044df3d|vehicular|Fail To Display D...|           TRUE|          TRUE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|\n",
      "|2006-01-01|00:00:00|          route: 134| NA| NA|   Haskell County|       A|      10|     5|    hispanic|       male|     5d6ea74869|vehicular|Minor Consume Alc...|           TRUE|         FALSE|citation|            TRUE|           FALSE|             FALSE|            TRUE|            NA|probable cause|           NA|          NA|           NA|          PU|          NA|\n",
      "|2006-01-01|00:00:00|          route: 134| NA| NA|   Haskell County|       A|      00|     5|       white|       male|     5d6ea74869|vehicular|Minor Consume Alc...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|\n",
      "|2006-01-01|00:01:00|route: 0059, mile...| NA| NA|   Wharton County|       C|      20|     2|       white|       male|     41cda6005f|vehicular|Speeding-10% or M...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|\n",
      "|2006-01-01|00:01:00|route: 0021, mile...| NA| NA|   Bastrop County|       C|      NA|     6|       black|     female|     8b99d7010d|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|\n",
      "|2006-01-01|00:01:00|route: 0238, mile...| NA| NA|   Calhoun County|       A|      NA|     3|       black|       male|     92f60bd84f|vehicular|No/Improper Licen...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|\n",
      "|2006-01-01|00:01:00|route: 0281, mile...| NA| NA|   Hidalgo County|       A|      42|     8|       white|       male|     3d49aa825d|vehicular|Speeding-10% or M...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|\n",
      "|2006-01-01|00:01:00|route: 0256, mile...| NA| NA|  Anderson County|       C|      NA|     6|       white|     female|     85d044df3d|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|\n",
      "|2006-01-01|00:01:00|route: 0410, mile...| NA| NA|     Bexar County|       B|      20|     3|    hispanic|     female|     083d70bcc5|vehicular|Ride, Not Secured...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|\n",
      "|2006-01-01|00:01:00|     route: FRONTAGE| NA| NA|   Cameron County|       A|      NA|     8|    hispanic|       male|     9d1b7b13f1|vehicular|No/Non-Compliant ...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|\n",
      "+----------+--------+--------------------+---+---+-----------------+--------+--------+------+------------+-----------+---------------+---------+--------------------+---------------+--------------+--------+----------------+----------------+------------------+----------------+--------------+--------------+-------------+------------+-------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop columns with name starting with 'raw_'\n",
    "df = df.drop(*[col for col in df.columns if col.startswith('raw_')])\n",
    "\n",
    "# Drop lat and Lng nulls\n",
    "df = df.dropna(subset=['lat', 'lng'])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19752786"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show number of rows\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove columns with more than 50% of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when, isnan, isnull\n",
    "\n",
    "# Calculate the number of records in the DataFrame\n",
    "total_records = df.count()\n",
    "\n",
    "# Create a new DataFrame that counts the number of nulls, NaNs, or Nones in each column\n",
    "null_counts = df.select([count(when((col(c) == 'NA') | (col(c) == 'na') | isnan(c) | isnull(c), c)).alias(c) for c in df.columns])\n",
    "\n",
    "# Convert the DataFrame to a dictionary\n",
    "null_counts_dict = {c: null_counts.first()[c] for c in null_counts.columns}\n",
    "\n",
    "# Drop columns where more than 50% of the values are null\n",
    "df = df.drop(*[c for c, null_count in null_counts_dict.items() if null_count / total_records > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+-------+-------+-----------+--------+--------+------+------------+-----------+---------------+----+---------+---------------+--------------+-------+----------------+----------------+------------------+----------------+--------------+------------+-------------+------------+-------------+------------+------------+\n",
      "|date|time|location|    lat|    lng|county_name|district|precinct|region|subject_race|subject_sex|officer_id_hash|type|violation|citation_issued|warning_issued|outcome|contraband_found|contraband_drugs|contraband_weapons|search_conducted|search_vehicle|search_basis|vehicle_color|vehicle_make|vehicle_model|vehicle_type|vehicle_year|\n",
      "+----+----+--------+-------+-------+-----------+--------+--------+------+------------+-----------+---------------+----+---------+---------------+--------------+-------+----------------+----------------+------------------+----------------+--------------+------------+-------------+------------+-------------+------------+------------+\n",
      "|   0|   0|      91|8152359|8152288|         99|    9161|12569006|     0|         236|        251|            250|   1|     1426|              1|             1|   1426|        19293219|        19293864|          19295854|            4385|        444674|    19293327|     14873559|     7671434|      8966745|        1451|     8921042|\n",
      "+----+----+--------+-------+-------+-----------+--------+--------+------+------------+-----------+---------------+----+---------+---------------+--------------+-------+----------------+----------------+------------------+----------------+--------------+------------+-------------+------------+-------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Print the null counts DataFrame\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+---+---+-----------------+------------+-----------+--------------------+----------------+--------------+------------+\n",
      "|      date|    time|            location|lat|lng|      county_name|subject_race|subject_sex|           violation|search_conducted|search_vehicle|vehicle_year|\n",
      "+----------+--------+--------------------+---+---+-----------------+------------+-----------+--------------------+----------------+--------------+------------+\n",
      "|2006-01-01|00:00:00|route: 0030, mile...| NA| NA|    Walker County|       white|     female|Drive On Improved...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0207, mile...| NA| NA|  Hansford County|       white|       male|Speeding-10% or M...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0105, mile...| NA| NA|Montgomery County|    hispanic|       male|Open Container in...|            TRUE|            NA|          NA|\n",
      "|2006-01-01|00:00:00|route: 0010, mile...| NA| NA|  Chambers County|       white|       male|Speeding Over Lim...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 1774, mile...| NA| NA|Montgomery County|       white|       male|No/Improper Licen...|            TRUE|            NA|          NA|\n",
      "|2006-01-01|00:00:00|route: 0035, mile...| NA| NA|      Frio County|    hispanic|       male|Speeding Over Lim...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0385, mile...| NA| NA|    Castro County|    hispanic|       male|No/Improper Licen...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0511, mile...| NA| NA|   Cameron County|    hispanic|       male|Fail to Maintain ...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0020, mile...| NA| NA|  Eastland County|    hispanic|       male|Speeding-10% or M...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0020, mile...| NA| NA| Van Zandt County|       white|       male|Speeding Over Lim...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0287, mile...| NA| NA|  Anderson County|       black|     female|Fail To Display D...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|          route: 134| NA| NA|   Haskell County|    hispanic|       male|Minor Consume Alc...|            TRUE|            NA|          NA|\n",
      "|2006-01-01|00:00:00|          route: 134| NA| NA|   Haskell County|       white|       male|Minor Consume Alc...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|route: 0059, mile...| NA| NA|   Wharton County|       white|       male|Speeding-10% or M...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|route: 0021, mile...| NA| NA|   Bastrop County|       black|     female|Speeding Over Lim...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|route: 0238, mile...| NA| NA|   Calhoun County|       black|       male|No/Improper Licen...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|route: 0281, mile...| NA| NA|   Hidalgo County|       white|       male|Speeding-10% or M...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|route: 0256, mile...| NA| NA|  Anderson County|       white|     female|Speeding Over Lim...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|route: 0410, mile...| NA| NA|     Bexar County|    hispanic|     female|Ride, Not Secured...|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|     route: FRONTAGE| NA| NA|   Cameron County|    hispanic|       male|No/Non-Compliant ...|           FALSE|         FALSE|          NA|\n",
      "+----------+--------+--------------------+---+---+-----------------+------------+-----------+--------------------+----------------+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop column officer_id_hash\n",
    "df = df.drop('officer_id_hash')\n",
    "# drop column district\n",
    "df = df.drop('district')\n",
    "# drop column region\n",
    "df = df.drop('region')\n",
    "# drop column type\n",
    "df = df.drop('type')\n",
    "# drop column citation_issued (meaningless)\n",
    "df = df.drop('citation_issued')\n",
    "# drop column warning_issued (meaningless)\n",
    "df = df.drop('warning_issued')\n",
    "\n",
    "### DROP FOR NOW OPTMIZATIONS\n",
    "\n",
    "# drop column outcome \n",
    "df = df.drop('outcome')\n",
    "# drop column vehicle_make\n",
    "df = df.drop('vehicle_make')\n",
    "# drop column vehicle_model\n",
    "df = df.drop('vehicle_model')\n",
    "# drop column vehicle_type\n",
    "df = df.drop('vehicle_type')\n",
    "# drop column violation\n",
    "# df = df.drop('violation')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intermediary save\n",
    "df.write.format('parquet').mode('overwrite').save('../data/tx_statewide_2020_04_01-002.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHot Encoding for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o530.load.\n: java.lang.UnsatisfiedLinkError: 'boolean org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(java.lang.String, int)'\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)\r\n\tat org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249)\r\n\tat org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)\r\n\tat org.apache.spark.util.HadoopFSUtils$.listLeafFiles(HadoopFSUtils.scala:180)\r\n\tat org.apache.spark.util.HadoopFSUtils$.$anonfun$parallelListLeafFilesInternal$1(HadoopFSUtils.scala:95)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\r\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\r\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\r\n\tat org.apache.spark.util.HadoopFSUtils$.parallelListLeafFilesInternal(HadoopFSUtils.scala:85)\r\n\tat org.apache.spark.util.HadoopFSUtils$.parallelListLeafFiles(HadoopFSUtils.scala:69)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.bulkListLeafFiles(InMemoryFileIndex.scala:162)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:133)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:96)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:68)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.createInMemoryFileIndex(DataSource.scala:539)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:405)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize a SparkSession\u001b[39;00m\n\u001b[0;32m      4\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataFrame Optimization\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/tx_statewide_2020_04_01-002.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# drop column type\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Theo Boucebaine\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:307\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Theo Boucebaine\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Theo Boucebaine\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\Theo Boucebaine\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o530.load.\n: java.lang.UnsatisfiedLinkError: 'boolean org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(java.lang.String, int)'\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)\r\n\tat org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249)\r\n\tat org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)\r\n\tat org.apache.spark.util.HadoopFSUtils$.listLeafFiles(HadoopFSUtils.scala:180)\r\n\tat org.apache.spark.util.HadoopFSUtils$.$anonfun$parallelListLeafFilesInternal$1(HadoopFSUtils.scala:95)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\r\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\r\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\r\n\tat org.apache.spark.util.HadoopFSUtils$.parallelListLeafFilesInternal(HadoopFSUtils.scala:85)\r\n\tat org.apache.spark.util.HadoopFSUtils$.parallelListLeafFiles(HadoopFSUtils.scala:69)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.bulkListLeafFiles(InMemoryFileIndex.scala:162)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:133)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:96)\r\n\tat org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:68)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.createInMemoryFileIndex(DataSource.scala:539)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:405)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('DataFrame Optimization') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.format('parquet').load('../data/tx_statewide_2020_04_01-002.parquet')\n",
    "\n",
    "# drop column type\n",
    "df = df.drop('type')\n",
    "# drop column citation_issued (meaningless)\n",
    "df = df.drop('citation_issued')\n",
    "# drop column warning_issued (meaningless)\n",
    "df = df.drop('warning_issued')\n",
    "\n",
    "### DROP FOR NOW OPTMIZATIONS\n",
    "\n",
    "# drop column outcome \n",
    "df = df.drop('outcome')\n",
    "# drop column vehicle_make\n",
    "df = df.drop('vehicle_make')\n",
    "# drop column vehicle_model\n",
    "df = df.drop('vehicle_model')\n",
    "# drop column vehicle_type\n",
    "df = df.drop('vehicle_type')\n",
    "# drop column violation\n",
    "# df = df.drop('violation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show different values in type column\n",
    "# df.select('search_conducted').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when, isnan, isnull\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# make subject_sex 1 if 'male' and 0 if 'female'\n",
    "df = df.withColumn(\"subject_sex\", when(col(\"subject_sex\") == \"male\", 1).otherwise(0).cast(\"integer\"))\n",
    "\n",
    "# make lat and long float\n",
    "df = df.withColumn(\"lat\", col(\"lat\").cast(\"float\"))\n",
    "df = df.withColumn(\"lng\", col(\"lng\").cast(\"float\"))\n",
    "\n",
    "# make subject_race 0 if 'white', 1 if 'black', 2 if 'hispanic', 3 if 'asian', 4 if 'other' and make it an integer column\n",
    "df = df.withColumn(\"subject_race\", when(col(\"subject_race\") == \"white\", 0)\n",
    "                                   .when(col(\"subject_race\") == \"black\", 1)\n",
    "                                   .when(col(\"subject_race\") == \"hispanic\", 2)\n",
    "                                   .when(col(\"subject_race\") == \"asian\", 3)\n",
    "                                   .otherwise(4).cast(\"integer\"))\n",
    "\n",
    "\n",
    "# make search_vehicle 1 if TRUE and 0 if FALSE else NA\n",
    "df = df.withColumn(\"search_vehicle\", when(col(\"search_vehicle\") == \"TRUE\", 1)\n",
    "                                    .when(col(\"search_vehicle\") == \"FALSE\", 0)\n",
    "                                    .otherwise(None).cast(\"integer\"))\n",
    "\n",
    "# make vehicle_year an integer column and fill NA with 0\n",
    "df = df.withColumn(\"vehicle_year\", col(\"vehicle_year\").cast(\"integer\"))\n",
    "df = df.withColumn(\"vehicle_year\", when(col(\"vehicle_year\").isNull(), 0).otherwise(col(\"vehicle_year\")))\n",
    "df = df.withColumn(\"vehicle_year\", when(col(\"vehicle_year\") < 1900, 0).otherwise(col(\"vehicle_year\")))\n",
    "df = df.withColumn(\"vehicle_year\", when(col(\"vehicle_year\") > 2022, 0).otherwise(col(\"vehicle_year\")))\n",
    "\n",
    "# date column is of format 'yyyy-mm-dd' and time column is of format 'hh:mm:ss': combine them into a single timestamp column\n",
    "from pyspark.sql.functions import to_timestamp, concat_ws\n",
    "\n",
    "df = df.withColumn(\"timestamp\", to_timestamp(concat_ws(\" \", col(\"date\"), col(\"time\")), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "# drop date and time columns\n",
    "df = df.drop(\"date\", \"time\")\n",
    "\n",
    "# make search_conducted 1 if TRUE or citation and 0 if FALSE else NA and make it an integer column\n",
    "from pyspark.sql.functions import col, when, to_timestamp, concat_ws\n",
    "\n",
    "df = df.withColumn(\"search_conducted\", when((col(\"search_conducted\") == \"TRUE\") | (col(\"search_conducted\") == \"citation\"), 1)\n",
    "                                      .when(col(\"search_conducted\") == \"FALSE\", 0)\n",
    "                                      .otherwise(None).cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Lowercase\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviolation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mviolation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Replace 'speeding' occurrences with 1, else 0\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviolation\u001b[39m\u001b[38;5;124m'\u001b[39m, when(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviolation\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeeding\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39motherwise(\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "# Lowercase\n",
    "df = df.withColumn('violation', col('violation').lower())\n",
    "\n",
    "# Replace 'speeding' occurrences with 1, else 0\n",
    "df = df.withColumn('violation', when(col('violation').contains('speeding'), 1).otherwise(0))\n",
    "\n",
    "# Convert the column to integer type\n",
    "df = df.withColumn('violation', col('violation').cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+---+---+-----------------+------------+-----------+---------+----------------+--------------+------------+\n",
      "|      date|    time|            location|lat|lng|      county_name|subject_race|subject_sex|violation|search_conducted|search_vehicle|vehicle_year|\n",
      "+----------+--------+--------------------+---+---+-----------------+------------+-----------+---------+----------------+--------------+------------+\n",
      "|2006-01-01|00:00:00|route: 0030, mile...| NA| NA|    Walker County|       white|     female|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0207, mile...| NA| NA|  Hansford County|       white|       male|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0105, mile...| NA| NA|Montgomery County|    hispanic|       male|        0|            TRUE|            NA|          NA|\n",
      "|2006-01-01|00:00:00|route: 0010, mile...| NA| NA|  Chambers County|       white|       male|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 1774, mile...| NA| NA|Montgomery County|       white|       male|        0|            TRUE|            NA|          NA|\n",
      "|2006-01-01|00:00:00|route: 0035, mile...| NA| NA|      Frio County|    hispanic|       male|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0385, mile...| NA| NA|    Castro County|    hispanic|       male|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0511, mile...| NA| NA|   Cameron County|    hispanic|       male|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0020, mile...| NA| NA|  Eastland County|    hispanic|       male|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0020, mile...| NA| NA| Van Zandt County|       white|       male|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|route: 0287, mile...| NA| NA|  Anderson County|       black|     female|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:00:00|          route: 134| NA| NA|   Haskell County|    hispanic|       male|        0|            TRUE|            NA|          NA|\n",
      "|2006-01-01|00:00:00|          route: 134| NA| NA|   Haskell County|       white|       male|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|route: 0059, mile...| NA| NA|   Wharton County|       white|       male|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|route: 0021, mile...| NA| NA|   Bastrop County|       black|     female|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|route: 0238, mile...| NA| NA|   Calhoun County|       black|       male|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|route: 0281, mile...| NA| NA|   Hidalgo County|       white|       male|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|route: 0256, mile...| NA| NA|  Anderson County|       white|     female|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|route: 0410, mile...| NA| NA|     Bexar County|    hispanic|     female|        0|           FALSE|         FALSE|          NA|\n",
      "|2006-01-01|00:01:00|     route: FRONTAGE| NA| NA|   Cameron County|    hispanic|       male|        0|           FALSE|         FALSE|          NA|\n",
      "+----------+--------+--------------------+---+---+-----------------+------------+-----------+---------+----------------+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('location', 'string'),\n",
       " ('lat', 'float'),\n",
       " ('lng', 'float'),\n",
       " ('county_name', 'string'),\n",
       " ('subject_race', 'int'),\n",
       " ('subject_sex', 'int'),\n",
       " ('search_conducted', 'int'),\n",
       " ('search_vehicle', 'int'),\n",
       " ('vehicle_year', 'int'),\n",
       " ('timestamp', 'timestamp')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+----------+----------------+------------+-----------+----------------+--------------+------------+-------------------+\n",
      "|            location|      lat|       lng|     county_name|subject_race|subject_sex|search_conducted|search_vehicle|vehicle_year|          timestamp|\n",
      "+--------------------+---------+----------+----------------+------------+-----------+----------------+--------------+------------+-------------------+\n",
      "|route: 0059, mile...|     NULL|      NULL|     Cass County|           0|          1|               0|             0|        1997|2012-03-27 22:10:00|\n",
      "|route: 0020, mile...|     NULL|      NULL|   Parker County|           0|          1|               0|             0|        2002|2012-03-27 22:11:00|\n",
      "|route: 0044, mile...|33.958683|-98.529686|  Wichita County|           0|          1|               0|             0|        2000|2012-03-27 22:11:00|\n",
      "|route: 1788, mile...|     NULL|      NULL|  Andrews County|           2|          1|               0|             0|        2011|2012-03-27 22:11:00|\n",
      "|route: 1788, mile...|     NULL|      NULL|  Andrews County|           0|          1|               0|             0|        2007|2012-03-27 22:11:00|\n",
      "|route: 0059, mile...|28.993633|  -96.6152|  Jackson County|           4|          1|               0|             0|        2002|2012-03-27 22:11:00|\n",
      "|route: 0035, mile...|     NULL|      NULL|     Webb County|           2|          1|               0|             0|        2010|2012-03-27 22:11:00|\n",
      "|route: 0010, mile...|29.838734| -94.73535| Chambers County|           0|          1|               0|             0|        2006|2012-03-27 22:12:00|\n",
      "|route: 0067, mile...|32.255566|-97.720314|Somervell County|           0|          0|               0|             0|        2004|2012-03-27 22:12:00|\n",
      "|route: 0087, mile...| 35.86605| -102.0781|    Moore County|           0|          1|               0|             0|           0|2012-03-27 22:13:00|\n",
      "|route: 0287, mile...|34.160767|  -99.3063|Wilbarger County|           0|          1|               0|             0|        2011|2012-03-27 22:13:00|\n",
      "|route: 0082, mile...| 33.65055|-96.483765|  Grayson County|           0|          1|               0|             0|        2001|2012-03-27 22:13:00|\n",
      "|route: 1001, mile...|33.194984| -94.92437|    Titus County|           0|          1|               0|             0|        2008|2012-03-27 22:13:00|\n",
      "|route: 0031, mile...|32.347935| -95.26462|    Smith County|           0|          0|               0|             0|        2010|2012-03-27 22:13:00|\n",
      "|route: COUNTY RD,...|29.655684|-95.658615|Fort Bend County|           2|          0|               0|             0|        2001|2012-03-27 22:13:00|\n",
      "|route: 0035, mile...|     NULL|      NULL|     Bell County|           2|          0|               0|             0|        2001|2012-03-27 22:13:00|\n",
      "|route: 0010, mile...| 29.53865|-98.077484|Guadalupe County|           0|          1|               0|             0|        2010|2012-03-27 22:13:00|\n",
      "|route: 0287, mile...|33.544983| -97.84963| Montague County|           0|          1|               0|             0|        1999|2012-03-27 22:14:00|\n",
      "|route: CITY ST, m...|     NULL|      NULL|Jefferson County|           0|          1|               0|             0|        1999|2012-03-27 22:49:00|\n",
      "|route: 0281, mile...|33.823566| -98.48548|   Archer County|           2|          1|               0|             0|        2003|2012-03-27 22:50:00|\n",
      "+--------------------+---------+----------+----------------+------------+-----------+----------------+--------------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19752786\n"
     ]
    }
   ],
   "source": [
    "# print length of dataframe\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "24/05/03 22:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/03 22:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/03 22:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 22:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# intermediary save\n",
    "df.write.format('parquet').mode('overwrite').save('../data/tx_statewide_2020_04_01-002_clean.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 4.0.0 not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow>=4.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"parsing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "# Read the parquet file\n",
    "df = spark.read.format('parquet').load('../data/tx_statewide_2020_04_01-002_clean.parquet')\n",
    "\n",
    "# remove the file if it exists\n",
    "if os.path.exists('../data/tx_statewide_2020_04_01-002_clean.csv'):\n",
    "    os.remove('../data/tx_statewide_2020_04_01-002_clean.csv')\n",
    "\n",
    "# Function to append a Pandas DataFrame to a CSV file\n",
    "def append_to_csv(pandas_df, filename, header=True, index=False):\n",
    "    pandas_df.to_csv(filename, mode='a', header=header, index=index)\n",
    "\n",
    "# Adjusted function to accept column names\n",
    "def write_partition_to_csv(column_names, iterator):\n",
    "    pandas_df = pd.DataFrame(list(iterator), columns=column_names)\n",
    "    if not pandas_df.empty:\n",
    "        append_to_csv(pandas_df, '../data/tx_statewide_2020_04_01-002_clean.csv', header=not os.path.exists('../data/tx_statewide_2020_04_01-002_clean.csv'), index=False)\n",
    "\n",
    "# Capture column names outside the function\n",
    "column_names = df.columns\n",
    "\n",
    "# Use partial to pass column names along with the iterator\n",
    "df.foreachPartition(partial(write_partition_to_csv, column_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
