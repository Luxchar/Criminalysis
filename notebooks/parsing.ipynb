{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "### We chose to parse the dataset from Stanford as it has more information and characteristics than the one from Kaggle. The dataset from Kaggle is a subset of the one from Stanford, so we decided to use the original one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------+--------------------+---+---+-----------------+--------+--------+------+------------+-----------+---------------+---------+--------------------+---------------+--------------+--------+----------------+----------------+------------------+----------------+--------------+--------------+-------------+------------+-------------+------------+------------+---------------+------------------------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|raw_row_number|      date|    time|            location|lat|lng|      county_name|district|precinct|region|subject_race|subject_sex|officer_id_hash|     type|           violation|citation_issued|warning_issued| outcome|contraband_found|contraband_drugs|contraband_weapons|search_conducted|search_vehicle|  search_basis|vehicle_color|vehicle_make|vehicle_model|vehicle_type|vehicle_year|raw_HA_RACE_SEX|raw_HA_SEARCH_PC_boolean|raw_HA_SEARCH_CONCENT_boolean|raw_HA_INCIDTO_ARREST_boolean|raw_HA_VEHICLE_INVENT_boolean|\n",
      "+--------------+----------+--------+--------------------+---+---+-----------------+--------+--------+------+------------+-----------+---------------+---------+--------------------+---------------+--------------+--------+----------------+----------------+------------------+----------------+--------------+--------------+-------------+------------+-------------+------------+------------+---------------+------------------------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|             1|2006-01-01|00:00:00|route: 0030, mile...| NA| NA|    Walker County|       C|      NA|     2|       white|     female|     b754c6abf4|vehicular|Drive On Improved...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             WF|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|             2|2006-01-01|00:00:00|route: 0207, mile...| NA| NA|  Hansford County|       B|      11|     5|       white|       male|     7621d63a65|vehicular|Speeding-10% or M...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             WM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|             3|2006-01-01|00:00:00|route: 0105, mile...| NA| NA|Montgomery County|       C|      20|     2|    hispanic|       male|     2c0d24dbbd|vehicular|Open Container in...|           TRUE|         FALSE|citation|            TRUE|           FALSE|             FALSE|            TRUE|            NA|probable cause|           NA|          NA|           NA|          SV|          NA|             HM|                    TRUE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|             4|2006-01-01|00:00:00|route: 0010, mile...| NA| NA|  Chambers County|       B|      NA|     2|       white|       male|     1abde6b2cf|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          SV|          NA|             WM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|             5|2006-01-01|00:00:00|route: 1774, mile...| NA| NA|Montgomery County|       C|      50|     2|       white|       male|     3f1120d85a|vehicular|No/Improper Licen...|           TRUE|          TRUE|citation|            TRUE|           FALSE|             FALSE|            TRUE|            NA|probable cause|           NA|          NA|           NA|          PA|          NA|             WM|                    TRUE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|             8|2006-01-01|00:00:00|route: 0035, mile...| NA| NA|      Frio County|       B|      NA|     3|    hispanic|       male|     bb8d7daa5d|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             HM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|             9|2006-01-01|00:00:00|route: 0385, mile...| NA| NA|    Castro County|       B|      NA|     5|    hispanic|       male|     46512c3e98|vehicular|No/Improper Licen...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|             HM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            10|2006-01-01|00:00:00|route: 0511, mile...| NA| NA|   Cameron County|       A|      21|     8|    hispanic|       male|     d71bcea4a5|vehicular|Fail to Maintain ...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PV|          NA|             HM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            11|2006-01-01|00:00:00|route: 0020, mile...| NA| NA|  Eastland County|       B|      20|     4|    hispanic|       male|     bfaf4ea0b6|vehicular|Speeding-10% or M...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             HM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            12|2006-01-01|00:00:00|route: 0020, mile...| NA| NA| Van Zandt County|       B|      NA|     1|       white|       male|     9c1f3a985a|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             WM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            13|2006-01-01|00:00:00|route: 0287, mile...| NA| NA|  Anderson County|       C|      40|     6|       black|     female|     85d044df3d|vehicular|Fail To Display D...|           TRUE|          TRUE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             BF|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            14|2006-01-01|00:00:00|          route: 134| NA| NA|   Haskell County|       A|      10|     5|    hispanic|       male|     5d6ea74869|vehicular|Minor Consume Alc...|           TRUE|         FALSE|citation|            TRUE|           FALSE|             FALSE|            TRUE|            NA|probable cause|           NA|          NA|           NA|          PU|          NA|             HM|                    TRUE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            16|2006-01-01|00:00:00|          route: 134| NA| NA|   Haskell County|       A|      00|     5|       white|       male|     5d6ea74869|vehicular|Minor Consume Alc...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|             WM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            17|2006-01-01|00:01:00|route: 0059, mile...| NA| NA|   Wharton County|       C|      20|     2|       white|       male|     41cda6005f|vehicular|Speeding-10% or M...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             WM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            18|2006-01-01|00:01:00|route: 0021, mile...| NA| NA|   Bastrop County|       C|      NA|     6|       black|     female|     8b99d7010d|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             BF|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            19|2006-01-01|00:01:00|route: 0238, mile...| NA| NA|   Calhoun County|       A|      NA|     3|       black|       male|     92f60bd84f|vehicular|No/Improper Licen...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|             BM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            20|2006-01-01|00:01:00|route: 0281, mile...| NA| NA|   Hidalgo County|       A|      42|     8|       white|       male|     3d49aa825d|vehicular|Speeding-10% or M...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|             WM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            21|2006-01-01|00:01:00|route: 0256, mile...| NA| NA|  Anderson County|       C|      NA|     6|       white|     female|     85d044df3d|vehicular|Speeding Over Lim...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             WF|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            22|2006-01-01|00:01:00|route: 0410, mile...| NA| NA|     Bexar County|       B|      20|     3|    hispanic|     female|     083d70bcc5|vehicular|Ride, Not Secured...|           TRUE|         FALSE|citation|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PU|          NA|             HF|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "|            23|2006-01-01|00:01:00|     route: FRONTAGE| NA| NA|   Cameron County|       A|      NA|     8|    hispanic|       male|     9d1b7b13f1|vehicular|No/Non-Compliant ...|          FALSE|          TRUE| warning|              NA|              NA|                NA|           FALSE|         FALSE|            NA|           NA|          NA|           NA|          PA|          NA|             HM|                   FALSE|                        FALSE|                        FALSE|                        FALSE|\n",
      "+--------------+----------+--------+--------------------+---+---+-----------------+--------+--------+------+------------+-----------+---------------+---------+--------------------+---------------+--------------+--------+----------------+----------------+------------------+----------------+--------------+--------------+-------------+------------+-------------+------------+------------+---------------+------------------------+-----------------------------+-----------------------------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('DataFrame Optimization') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the DataFrame\n",
    "df = spark.read.format('csv').option('header', 'true').load('../data/tx_statewide_2020_04_01-002.csv')\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove columns with name starting with \"raw_\" as they are not useful for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with name starting with 'raw_'\n",
    "df = df.drop(*[col for col in df.columns if col.startswith('raw_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove columns with more than 50% of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve-DataFrame\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(Unknown Source)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.accept(Unknown Source)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(Unknown Source)\n",
      "\tat java.base/java.net.ServerSocket.platformImplAccept(Unknown Source)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(Unknown Source)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(Unknown Source)\n",
      "\tat java.base/java.net.ServerSocket.accept(Unknown Source)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:65)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, when, isnan, isnull\n",
    "\n",
    "# Calculate the number of records in the DataFrame\n",
    "total_records = df.count()\n",
    "\n",
    "# Create a new DataFrame that counts the number of nulls, NaNs, or Nones in each column\n",
    "null_counts = df.select([count(when((col(c) == 'NA') | (col(c) == 'na') | isnan(c) | isnull(c), c)).alias(c) for c in df.columns])\n",
    "\n",
    "# Convert the DataFrame to a dictionary\n",
    "null_counts_dict = {c: null_counts.first()[c] for c in null_counts.columns}\n",
    "\n",
    "# Drop columns where more than 50% of the values are null\n",
    "df = df.drop(*[c for c, null_count in null_counts_dict.items() if null_count / total_records > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 119:=====================================================> (39 + 1) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+-------+-------+-----------+--------+--------+------+------------+-----------+---------------+----+---------+---------------+--------------+-------+----------------+----------------+------------------+----------------+--------------+------------+-------------+------------+-------------+------------+------------+\n",
      "|date|time|location|    lat|    lng|county_name|district|precinct|region|subject_race|subject_sex|officer_id_hash|type|violation|citation_issued|warning_issued|outcome|contraband_found|contraband_drugs|contraband_weapons|search_conducted|search_vehicle|search_basis|vehicle_color|vehicle_make|vehicle_model|vehicle_type|vehicle_year|\n",
      "+----+----+--------+-------+-------+-----------+--------+--------+------+------------+-----------+---------------+----+---------+---------------+--------------+-------+----------------+----------------+------------------+----------------+--------------+------------+-------------+------------+-------------+------------+------------+\n",
      "|   0|   0|      91|8152359|8152288|         99|    9161|12569006|     0|         236|        251|            250|   1|     1426|              1|             1|   1426|        19293219|        19293864|          19295854|            4385|        444674|    19293327|     14873559|     7671434|      8966745|        1451|     8921042|\n",
      "+----+----+--------+-------+-------+-----------+--------+--------+------+------------+-----------+---------------+----+---------+---------------+--------------+-------+----------------+----------------+------------------+----------------+--------------+------------+-------------+------------+-------------+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# # Print the null counts DataFrame\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column officer_id_hash\n",
    "df = df.drop('officer_id_hash')\n",
    "# drop column district\n",
    "df = df.drop('district')\n",
    "# drop column region\n",
    "df = df.drop('region')\n",
    "# drop column type\n",
    "df = df.drop('type')\n",
    "# drop column citation_issued (meaningless)\n",
    "df = df.drop('citation_issued')\n",
    "# drop column warning_issued (meaningless)\n",
    "df = df.drop('warning_issued')\n",
    "\n",
    "### DROP FOR NOW OPTMIZATIONS\n",
    "\n",
    "# drop column outcome \n",
    "df = df.drop('outcome')\n",
    "# drop column vehicle_make\n",
    "df = df.drop('vehicle_make')\n",
    "# drop column vehicle_model\n",
    "df = df.drop('vehicle_model')\n",
    "# drop column vehicle_type\n",
    "df = df.drop('vehicle_type')\n",
    "# drop column violation\n",
    "df = df.drop('violation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/03 21:58:27 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/05/03 21:58:27 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/03 21:58:27 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/03 21:58:27 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/03 21:58:27 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 21:58:27 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 21:58:27 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/03 21:58:27 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/03 21:58:27 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "24/05/03 21:58:33 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/03 21:58:33 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/03 21:58:33 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 21:58:33 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 21:58:33 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/03 21:58:33 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/03 21:58:33 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/03 21:58:33 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/05/03 21:58:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/05/03 21:58:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/03 21:58:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/03 21:58:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/03 21:58:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 21:58:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 21:58:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/03 21:58:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/03 21:58:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/03 21:58:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/03 21:58:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "24/05/03 21:58:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/03 21:58:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/03 21:58:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 21:58:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/03 21:58:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# intermediary save\n",
    "df.write.format('parquet').mode('overwrite').save('../data/tx_statewide_2020_04_01-002.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHot Encoding for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('DataFrame Optimization') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.format('parquet').load('../data/tx_statewide_2020_04_01-002.parquet')\n",
    "\n",
    "# drop column type\n",
    "df = df.drop('type')\n",
    "# drop column citation_issued (meaningless)\n",
    "df = df.drop('citation_issued')\n",
    "# drop column warning_issued (meaningless)\n",
    "df = df.drop('warning_issued')\n",
    "\n",
    "### DROP FOR NOW OPTMIZATIONS\n",
    "\n",
    "# drop column outcome \n",
    "df = df.drop('outcome')\n",
    "# drop column vehicle_make\n",
    "df = df.drop('vehicle_make')\n",
    "# drop column vehicle_model\n",
    "df = df.drop('vehicle_model')\n",
    "# drop column vehicle_type\n",
    "df = df.drop('vehicle_type')\n",
    "# drop column violation\n",
    "df = df.drop('violation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show different values in type column\n",
    "# df.select('search_conducted').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when, isnan, isnull\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# make subject_sex 1 if 'male' and 0 if 'female'\n",
    "df = df.withColumn(\"subject_sex\", when(col(\"subject_sex\") == \"male\", 1).otherwise(0).cast(\"integer\"))\n",
    "\n",
    "# make lat and long float\n",
    "df = df.withColumn(\"lat\", col(\"lat\").cast(\"float\"))\n",
    "df = df.withColumn(\"lng\", col(\"lng\").cast(\"float\"))\n",
    "\n",
    "# make subject_race 0 if 'white', 1 if 'black', 2 if 'hispanic', 3 if 'asian', 4 if 'other' and make it an integer column\n",
    "df = df.withColumn(\"subject_race\", when(col(\"subject_race\") == \"white\", 0)\n",
    "                                   .when(col(\"subject_race\") == \"black\", 1)\n",
    "                                   .when(col(\"subject_race\") == \"hispanic\", 2)\n",
    "                                   .when(col(\"subject_race\") == \"asian\", 3)\n",
    "                                   .otherwise(4).cast(\"integer\"))\n",
    "\n",
    "\n",
    "# make search_vehicle 1 if TRUE and 0 if FALSE else NA\n",
    "df = df.withColumn(\"search_vehicle\", when(col(\"search_vehicle\") == \"TRUE\", 1)\n",
    "                                    .when(col(\"search_vehicle\") == \"FALSE\", 0)\n",
    "                                    .otherwise(None).cast(\"integer\"))\n",
    "\n",
    "# make vehicle_year an integer column and fill NA with 0\n",
    "df = df.withColumn(\"vehicle_year\", col(\"vehicle_year\").cast(\"integer\"))\n",
    "df = df.withColumn(\"vehicle_year\", when(col(\"vehicle_year\").isNull(), 0).otherwise(col(\"vehicle_year\")))\n",
    "df = df.withColumn(\"vehicle_year\", when(col(\"vehicle_year\") < 1900, 0).otherwise(col(\"vehicle_year\")))\n",
    "df = df.withColumn(\"vehicle_year\", when(col(\"vehicle_year\") > 2022, 0).otherwise(col(\"vehicle_year\")))\n",
    "\n",
    "# date column is of format 'yyyy-mm-dd' and time column is of format 'hh:mm:ss': combine them into a single timestamp column\n",
    "from pyspark.sql.functions import to_timestamp, concat_ws\n",
    "\n",
    "df = df.withColumn(\"timestamp\", to_timestamp(concat_ws(\" \", col(\"date\"), col(\"time\")), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "# drop date and time columns\n",
    "df = df.drop(\"date\", \"time\")\n",
    "\n",
    "# make search_conducted 1 if TRUE or citation and 0 if FALSE else NA and make it an integer column\n",
    "from pyspark.sql.functions import col, when, to_timestamp, concat_ws\n",
    "\n",
    "df = df.withColumn(\"search_conducted\", when((col(\"search_conducted\") == \"TRUE\") | (col(\"search_conducted\") == \"citation\"), 1)\n",
    "                                      .when(col(\"search_conducted\") == \"FALSE\", 0)\n",
    "                                      .otherwise(None).cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('location', 'string'),\n",
       " ('lat', 'float'),\n",
       " ('lng', 'float'),\n",
       " ('county_name', 'string'),\n",
       " ('subject_race', 'int'),\n",
       " ('subject_sex', 'int'),\n",
       " ('search_conducted', 'int'),\n",
       " ('search_vehicle', 'int'),\n",
       " ('vehicle_year', 'int'),\n",
       " ('timestamp', 'timestamp')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+----------+----------------+------------+-----------+----------------+--------------+------------+-------------------+\n",
      "|            location|      lat|       lng|     county_name|subject_race|subject_sex|search_conducted|search_vehicle|vehicle_year|          timestamp|\n",
      "+--------------------+---------+----------+----------------+------------+-----------+----------------+--------------+------------+-------------------+\n",
      "|route: 0059, mile...|     NULL|      NULL|     Cass County|           0|          1|               0|             0|        1997|2012-03-27 22:10:00|\n",
      "|route: 0020, mile...|     NULL|      NULL|   Parker County|           0|          1|               0|             0|        2002|2012-03-27 22:11:00|\n",
      "|route: 0044, mile...|33.958683|-98.529686|  Wichita County|           0|          1|               0|             0|        2000|2012-03-27 22:11:00|\n",
      "|route: 1788, mile...|     NULL|      NULL|  Andrews County|           2|          1|               0|             0|        2011|2012-03-27 22:11:00|\n",
      "|route: 1788, mile...|     NULL|      NULL|  Andrews County|           0|          1|               0|             0|        2007|2012-03-27 22:11:00|\n",
      "|route: 0059, mile...|28.993633|  -96.6152|  Jackson County|           4|          1|               0|             0|        2002|2012-03-27 22:11:00|\n",
      "|route: 0035, mile...|     NULL|      NULL|     Webb County|           2|          1|               0|             0|        2010|2012-03-27 22:11:00|\n",
      "|route: 0010, mile...|29.838734| -94.73535| Chambers County|           0|          1|               0|             0|        2006|2012-03-27 22:12:00|\n",
      "|route: 0067, mile...|32.255566|-97.720314|Somervell County|           0|          0|               0|             0|        2004|2012-03-27 22:12:00|\n",
      "|route: 0087, mile...| 35.86605| -102.0781|    Moore County|           0|          1|               0|             0|           0|2012-03-27 22:13:00|\n",
      "|route: 0287, mile...|34.160767|  -99.3063|Wilbarger County|           0|          1|               0|             0|        2011|2012-03-27 22:13:00|\n",
      "|route: 0082, mile...| 33.65055|-96.483765|  Grayson County|           0|          1|               0|             0|        2001|2012-03-27 22:13:00|\n",
      "|route: 1001, mile...|33.194984| -94.92437|    Titus County|           0|          1|               0|             0|        2008|2012-03-27 22:13:00|\n",
      "|route: 0031, mile...|32.347935| -95.26462|    Smith County|           0|          0|               0|             0|        2010|2012-03-27 22:13:00|\n",
      "|route: COUNTY RD,...|29.655684|-95.658615|Fort Bend County|           2|          0|               0|             0|        2001|2012-03-27 22:13:00|\n",
      "|route: 0035, mile...|     NULL|      NULL|     Bell County|           2|          0|               0|             0|        2001|2012-03-27 22:13:00|\n",
      "|route: 0010, mile...| 29.53865|-98.077484|Guadalupe County|           0|          1|               0|             0|        2010|2012-03-27 22:13:00|\n",
      "|route: 0287, mile...|33.544983| -97.84963| Montague County|           0|          1|               0|             0|        1999|2012-03-27 22:14:00|\n",
      "|route: CITY ST, m...|     NULL|      NULL|Jefferson County|           0|          1|               0|             0|        1999|2012-03-27 22:49:00|\n",
      "|route: 0281, mile...|33.823566| -98.48548|   Archer County|           2|          1|               0|             0|        2003|2012-03-27 22:50:00|\n",
      "+--------------------+---------+----------+----------------+------------+-----------+----------------+--------------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19752786\n"
     ]
    }
   ],
   "source": [
    "# print length of dataframe\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/03 22:50:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "24/05/03 22:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/03 22:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/03 22:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/03 22:50:18 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/03 22:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# intermediary save\n",
    "df.write.format('parquet').mode('overwrite').save('../data/tx_statewide_2020_04_01-002_clean.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 4.0.0 not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow>=4.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"parsing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "# Read the parquet file\n",
    "df = spark.read.format('parquet').load('../data/tx_statewide_2020_04_01-002_clean.parquet')\n",
    "\n",
    "# remove the file if it exists\n",
    "if os.path.exists('../data/tx_statewide_2020_04_01-002_clean.csv'):\n",
    "    os.remove('../data/tx_statewide_2020_04_01-002_clean.csv')\n",
    "\n",
    "# Function to append a Pandas DataFrame to a CSV file\n",
    "def append_to_csv(pandas_df, filename, header=True, index=False):\n",
    "    pandas_df.to_csv(filename, mode='a', header=header, index=index)\n",
    "\n",
    "# Adjusted function to accept column names\n",
    "def write_partition_to_csv(column_names, iterator):\n",
    "    pandas_df = pd.DataFrame(list(iterator), columns=column_names)\n",
    "    if not pandas_df.empty:\n",
    "        append_to_csv(pandas_df, '../data/tx_statewide_2020_04_01-002_clean.csv', header=not os.path.exists('../data/tx_statewide_2020_04_01-002_clean.csv'), index=False)\n",
    "\n",
    "# Capture column names outside the function\n",
    "column_names = df.columns\n",
    "\n",
    "# Use partial to pass column names along with the iterator\n",
    "df.foreachPartition(partial(write_partition_to_csv, column_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
